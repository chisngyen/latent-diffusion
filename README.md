# Latent Diffusion Models

[arXiv](https://arxiv.org/abs/2112.10752) | [BibTeX](#bibtex)

<p align="center">
<img src=assets/results.gif />
</p>

[**High-Resolution Image Synthesis with Latent Diffusion Models**](https://arxiv.org/abs/2112.10752)<br/>
[Robin Rombach](https://github.com/rromb)\*,
[Andreas Blattmann](https://github.com/ablattmann)\*,
[Dominik Lorenz](https://github.com/qp-qp)\,
[Patrick Esser](https://github.com/pesser),
[BjÃ¶rn Ommer](https://hci.iwr.uni-heidelberg.de/Staff/bommer)<br/>

<p align="center">
<img src=assets/modelfigure.png />
</p>

## Requirements

```
conda env create -f environment.yaml
conda activate ldm
```

# ÄÃ¡nh giÃ¡ Latent Diffusion Models

ÄÃ¡nh giÃ¡ toÃ n diá»‡n cho cÃ¡c mÃ´ hÃ¬nh Latent Diffusion qua ba tÃ¡c vá»¥ chÃ­nh: **Inpainting**, **Super Resolution**, vÃ  **Text-to-Image Generation**.

## ğŸ“‹ Má»¥c Lá»¥c

- [Tá»•ng Quan](#tá»•ng-quan)
- [YÃªu Cáº§u Há»‡ Thá»‘ng](#yÃªu-cáº§u-há»‡-thá»‘ng)
- [CÃ i Äáº·t](#cÃ i-Ä‘áº·t)
- [Thiáº¿t Láº­p Dataset](#thiáº¿t-láº­p-dataset)
- [CÃ¡ch Sá»­ Dá»¥ng](#cÃ¡ch-sá»­-dá»¥ng)
- [Metrics ÄÃ¡nh GiÃ¡](#metrics-Ä‘Ã¡nh-giÃ¡)
- [Cáº¥u TrÃºc Output](#cáº¥u-trÃºc-output)

## ğŸ¯ Tá»•ng Quan

Bá»™ cÃ´ng cá»¥ Ä‘Ã¡nh giÃ¡ nÃ y cung cáº¥p benchmark chuáº©n hÃ³a cho ba nhiá»‡m vá»¥ chÃ­nh cá»§a mÃ´ hÃ¬nh diffusion:

### 1. **ÄÃ¡nh GiÃ¡ Inpainting**

- **Dataset**: SDXL Inpainting Lights
- **Metrics**: FID, LPIPS, Edge Consistency, SSIM, PSNR
- **Má»¥c Ä‘Ã­ch**: ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng hoÃ n thiá»‡n áº£nh vÃ  Ä‘á»™ mÆ°á»£t mÃ  cá»§a ranh giá»›i

### 2. **ÄÃ¡nh GiÃ¡ Super Resolution**

- **Dataset**: Urban100
- **Metrics**: FID, Precision/Recall, Visual Quality, Edge Consistency
- **Má»¥c Ä‘Ã­ch**: ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng upscaling vÃ  báº£o toÃ n chi tiáº¿t

### 3. **ÄÃ¡nh GiÃ¡ Text-to-Image**

- **Dataset**: Flickr30k
- **Metrics**: FID, Precision/Recall, CLIP Score
- **Má»¥c Ä‘Ã­ch**: Äo lÆ°á»ng sá»± phÃ¹ há»£p giá»¯a text-image vÃ  cháº¥t lÆ°á»£ng sinh áº£nh

## ğŸ›  YÃªu Cáº§u Há»‡ Thá»‘ng

### Dependencies CÆ¡ Báº£n

```
torch>=1.9.0
torchvision>=0.10.0
numpy>=1.21.0
pillow>=8.0.0
opencv-python>=4.5.0
scikit-image>=0.18.0
scipy>=1.7.0
tqdm>=4.62.0
omegaconf>=2.1.0
einops>=0.3.0
```

### Dependencies TÃ¹y Chá»n

```
lpips>=0.1.4           # Cho perceptual similarity
clip-by-openai>=1.0    # Cho CLIP scores  
pytorch-fid>=0.3.0     # Cho tÃ­nh toÃ¡n FID
datasets>=2.0.0        # Cho xá»­ lÃ½ dataset
matplotlib>=3.5.0      # Cho visualization
```

### Dependencies MÃ´ HÃ¬nh

```
# CÃ¡c component cá»§a mÃ´ hÃ¬nh latent diffusion
ldm/                   # Modules mÃ´ hÃ¬nh local
main.py               # Utilities khá»Ÿi táº¡o mÃ´ hÃ¬nh
```

## ğŸ“¦ CÃ i Äáº·t

### 1. Clone Repository

```bash
git clone <your-repo-url>
cd latent-diffusion
```

### 2. CÃ i Äáº·t Dependencies

```bash
# CÃ i Ä‘áº·t cÆ¡ báº£n
pip install torch torchvision torchaudio
pip install numpy pillow opencv-python scikit-image scipy tqdm omegaconf einops

# TÃ¹y chá»n nhÆ°ng Ä‘Æ°á»£c khuyáº¿n nghá»‹
pip install lpips clip-by-openai pytorch-fid datasets matplotlib

# Cho xá»­ lÃ½ dataset
pip install datasets
```

### 3. Kiá»ƒm Tra CÃ i Äáº·t

```bash
python -c "import torch, torchvision, cv2, lpips, clip; print('âœ… Táº¥t cáº£ dependencies Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t')"
```

## ğŸ’¾ Thiáº¿t Láº­p Dataset

### ğŸ“ 1. Dataset Inpainting

#### Thiáº¿t Láº­p Cáº¥u TrÃºc Dá»¯ Liá»‡u

```bash
cd evaluation_scripts/inpainting/
python load_data.py
python setup_data.py
```

**Cáº¥u TrÃºc Mong Äá»£i:**

```
data/
â”œâ”€â”€ sdxl-inpainting-lights/          # Dataset gá»‘c
â””â”€â”€ inpainting_dataset/              # Dataset Ä‘Ã£ xá»­ lÃ½
    â”œâ”€â”€ images/                      # áº¢nh gá»‘c (PNG)
    â”œâ”€â”€ masked_images/              # áº¢nh Ä‘Ã£ mask (PNG)  
    â”œâ”€â”€ masks/                      # Binary masks (PNG)
    â”œâ”€â”€ texts/                      # Text prompts (TXT)
    â”œâ”€â”€ metadata.json               # Metadata dataset
    â””â”€â”€ stats.json                  # Thá»‘ng kÃª dataset
```

### ğŸ” 2. Dataset Super Resolution

#### Táº£i dataset

```bash
https://www.kaggle.com/datasets/harshraone/urban100
```

**Cáº¥u TrÃºc Mong Äá»£i:**

```
data/super-resolution_dataset/
â”œâ”€â”€ X2/                             # Scale factor 2
â”‚   â”œâ”€â”€ HIGH/                       # áº¢nh HR
â”‚   â”‚   â””â”€â”€ *_SRF_2_HR.*
â”‚   â””â”€â”€ LOW/                        # áº¢nh LR  
â”‚       â””â”€â”€ *_SRF_2_LR.*
â””â”€â”€ X4/                             # Scale factor 4
    â”œâ”€â”€ HIGH/                       # áº¢nh HR
    â”‚   â””â”€â”€ *_SRF_4_HR.*
    â””â”€â”€ LOW/                        # áº¢nh LR
        â””â”€â”€ *_SRF_4_LR.*
```

### ğŸ“¸ 3. Dataset Text-to-Image

#### Táº£i dataset

```bash
https://www.kaggle.com/datasets/adityajn105/flickr30k
```

**Cáº¥u TrÃºc Mong Äá»£i:**

```
data/text2img_dataset/
â”œâ”€â”€ images/                         # Files áº£nh
â”‚   â”œâ”€â”€ 1000092795.jpg
â”‚   â”œâ”€â”€ 1000092795.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ captions.txt                    # CSV vá»›i image_name,caption
```

**Format captions.txt:**

```csv
image_name,caption
1000092795.jpg,Two young girls riding their scooters on a sidewalk.
1001773457.jpg,A brown dog is running in a field with tall grass.
...

## ğŸš€ CÃ¡ch Sá»­ Dá»¥ng
### LÆ°u Ã½: Giáº£i nÃ©n cÃ¡c file models.zip cá»§a cÃ¡c models trÆ°á»›c khi sá»­ dá»¥ng (models/first_stage_models + models/ldm)

### ğŸ¨ 1. ÄÃ¡nh GiÃ¡ Inpainting

#### CÃ¡ch Sá»­ Dá»¥ng CÆ¡ Báº£n
```bash
cd evaluation_scripts/inpainting/
python evaluation_inpainting.py \
    --data_dir ../../data/inpainting_dataset \
    --output_dir ../../evaluation/inpainting_results \
    --config ../../models/ldm/inpainting_big/config.yaml \
    --model ../../models/ldm/inpainting_big/last.ckpt \
    --max_samples 100 \
    --steps 50
```

#### TÃ¹y Chá»n NÃ¢ng Cao

```bash
python evaluation_inpainting.py \
    --data_dir ../../data/inpainting_dataset \
    --output_dir ../../evaluation/inpainting_full \
    --config ../../models/ldm/inpainting_big/config.yaml \
    --model ../../models/ldm/inpainting_big/last.ckpt \
    --max_samples 1000 \          # Nhiá»u samples hÆ¡n cho Ä‘Ã¡nh giÃ¡ toÃ n diá»‡n
    --steps 100                   # Nhiá»u steps hÆ¡n cho cháº¥t lÆ°á»£ng tá»‘t hÆ¡n
```

### ğŸ” 2. ÄÃ¡nh GiÃ¡ Super Resolution

#### Scale Factor 2

```bash
cd evaluation_scripts/super-resolution/
python evaluation_sr.py \
    --dataset_path ../../data/super-resolution_dataset \
    --config ../../models/ldm/bsr_sr/config.yaml \
    --checkpoint ../../models/ldm/bsr_sr/model.ckpt \
    --scale 2 \
    --output_dir ../../evaluation/sr_x2_results
```

#### Scale Factor 4

```bash
python evaluation_sr.py \
    --dataset_path ../../data/super-resolution_dataset \
    --config ../../models/ldm/bsr_sr/config.yaml \
    --checkpoint ../../models/ldm/bsr_sr/model.ckpt \
    --scale 4 \
    --output_dir ../../evaluation/sr_x4_results
```

### ğŸ“ 3. ÄÃ¡nh GiÃ¡ Text-to-Image

#### Test Nhanh (LÆ°u 10% áº£nh)

```bash
cd evaluation_scripts/text2img/
python evaluation_text2img.py \
    --dataset_root ../../data/text2img_dataset \
    --config_path ../../configs/latent-diffusion/txt2img-1p4B-eval.yaml \
    --model_path ../../models/ldm/text2img-large/model.ckpt \
    --output_dir ../../evaluation/text2img_test \
    --max_samples 100 \
    --save_images_ratio 0.1 \
    --ddim_steps 50
```

#### ÄÃ¡nh GiÃ¡ Äáº§y Äá»§

```bash
python evaluation_text2img.py \
    --dataset_root ../../data/text2img_dataset \
    --config_path ../../configs/latent-diffusion/txt2img-1p4B-eval.yaml \
    --model_path ../../models/ldm/text2img-large/model.ckpt \
    --output_dir ../../evaluation/text2img_full \
    --max_samples 1000 \
    --save_images_ratio 1.0 \     # LÆ°u táº¥t cáº£ áº£nh Ä‘Æ°á»£c sinh
    --ddim_steps 100 \
    --scale 7.5                   # Classifier-free guidance scale
```

## ğŸ“Š Metrics ÄÃ¡nh GiÃ¡

### ğŸ¨ Metrics Inpainting


| Metric               | MÃ´ Táº£                                                       | Khoáº£ng | Tá»‘t HÆ¡n     |
| ---------------------- | --------------------------------------------------------------- | --------- | --------------- |
| **FID Score**        | FrÃ©chet Inception Distance - Äá»™ thá»±c cá»§a áº£nh tá»•ng thá»ƒ | [0, âˆ) | â†“ Tháº¥p hÆ¡n |
| **LPIPS**            | Learned Perceptual Image Patch Similarity                     | [0, 1]  | â†“ Tháº¥p hÆ¡n |
| **Edge Consistency** | Äá»™ mÆ°á»£t mÃ  ranh giá»›i táº¡i viá»n mask                    | [0, 1]  | â†‘ Cao hÆ¡n   |
| **SSIM**             | Structural Similarity Index                                   | [0, 1]  | â†‘ Cao hÆ¡n   |
| **PSNR**             | Peak Signal-to-Noise Ratio                                    | [0, âˆ) | â†‘ Cao hÆ¡n   |

**CÃ¡ch ÄÃ¡nh GiÃ¡ Cháº¥t LÆ°á»£ng:**

- **FID < 30**: ğŸŒŸ Xuáº¥t sáº¯c
- **FID < 50**: âœ… Ráº¥t tá»‘t
- **FID < 100**: ğŸ‘ Tá»‘t
- **LPIPS < 0.1**: ğŸŒŸ Cháº¥t lÆ°á»£ng perceptual xuáº¥t sáº¯c
- **Edge Consistency > 0.8**: ğŸŒŸ Pha trá»™n xuáº¥t sáº¯c

### ğŸ” Metrics Super Resolution


| Metric        | MÃ´ Táº£                              | Khoáº£ng | Tá»‘t HÆ¡n     |
| --------------- | -------------------------------------- | --------- | --------------- |
| **FID Score** | Äá»™ tÆ°Æ¡ng Ä‘á»“ng phÃ¢n phá»‘i áº£nh | [0, âˆ) | â†“ Tháº¥p hÆ¡n |
| **Precision** | Cháº¥t lÆ°á»£ng sample Ä‘Æ°á»£c sinh    | [0, 1]  | â†‘ Cao hÆ¡n   |
| **Recall**    | Äá»™ bao phá»§ phÃ¢n phá»‘i thá»±c      | [0, 1]  | â†‘ Cao hÆ¡n   |
| **SSIM**      | Báº£o toÃ n cáº¥u trÃºc                | [0, 1]  | â†‘ Cao hÆ¡n   |
| **PSNR**      | Cháº¥t lÆ°á»£ng giáº£m nhiá»…u           | [0, âˆ) | â†‘ Cao hÆ¡n   |
| **LPIPS**     | Äá»™ tÆ°Æ¡ng Ä‘á»“ng perceptual       | [0, 1]  | â†“ Tháº¥p hÆ¡n |

### ğŸ“ Metrics Text-to-Image


| Metric         | MÃ´ Táº£                             | Khoáº£ng | Tá»‘t HÆ¡n     |
| ---------------- | ------------------------------------- | --------- | --------------- |
| **FID Score**  | PhÃ¢n phá»‘i áº£nh sinh vs áº£nh thá»±c | [0, âˆ) | â†“ Tháº¥p hÆ¡n |
| **CLIP Score** | Äá»™ phÃ¹ há»£p semantic text-image  | [-1, 1] | â†‘ Cao hÆ¡n   |
| **Precision**  | Cháº¥t lÆ°á»£ng sample Ä‘Æ°á»£c sinh   | [0, 1]  | â†‘ Cao hÆ¡n   |
| **Recall**     | Äá»™ bao phá»§ phÃ¢n phá»‘i thá»±c     | [0, 1]  | â†‘ Cao hÆ¡n   |

**CÃ¡ch ÄÃ¡nh GiÃ¡ CLIP Score:**

- **> 0.3**: ğŸŒŸ Äá»™ phÃ¹ há»£p text-image xuáº¥t sáº¯c
- **> 0.25**: âœ… Äá»™ phÃ¹ há»£p tá»‘t
- **> 0.2**: ğŸ‘ Äá»™ phÃ¹ há»£p khÃ¡

## ğŸ“ Cáº¥u TrÃºc Output

### Káº¿t Quáº£ Inpainting

```
evaluation/inpainting_results/
â”œâ”€â”€ evaluation_results.json         # Metrics Ä‘áº§y Ä‘á»§ vÃ  logs
â”œâ”€â”€ inpainted_00001.png             # Káº¿t quáº£ máº«u
â”œâ”€â”€ inpainted_00002.png
â””â”€â”€ ...
```

### Káº¿t Quáº£ Super Resolution

```
evaluation/sr_x4_results/
â”œâ”€â”€ urban100_x4_results.json        # Metrics Ä‘Ã¡nh giÃ¡
â”œâ”€â”€ sample_results/                 # 10 káº¿t quáº£ Ä‘áº§u tiÃªn
â”‚   â”œâ”€â”€ result_000_sr.png           # Super-resolved
â”‚   â”œâ”€â”€ result_000_hr.png           # Ground truth
â”‚   â””â”€â”€ ...
```

### Káº¿t Quáº£ Text-to-Image

```
evaluation/text2img_full/
â”œâ”€â”€ evaluation_results.txt          # Káº¿t quáº£ chi tiáº¿t
â”œâ”€â”€ generated_00001.png             # áº¢nh Ä‘Æ°á»£c sinh
â”œâ”€â”€ generated_00002.png
â””â”€â”€ ...
```

# BibTeX

```
@misc{rombach2021highresolution,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and BjÃ¶rn Ommer},
      year={2021},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{https://doi.org/10.48550/arxiv.2204.11824,
  doi = {10.48550/ARXIV.2204.11824},
  url = {https://arxiv.org/abs/2204.11824},
  author = {Blattmann, Andreas and Rombach, Robin and Oktay, Kaan and Ommer, BjÃ¶rn},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Retrieval-Augmented Diffusion Models},
  publisher = {arXiv},
  year = {2022},  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


```
